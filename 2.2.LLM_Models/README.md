# 2.2: ë‹¤ì–‘í•œ LLM ëª¨ë¸ ì—°ë™í•˜ê¸°

## ğŸ“– í•™ìŠµ ëª©í‘œ

ì´ ê°•ì˜ë¥¼ ë§ˆì¹œ í›„ ë‹¤ìŒì„ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
- **ë‹¤ì–‘í•œ LLM ì œê³µì**(OpenAI, Anthropic, Ollama)ë¥¼ Spring AIë¡œ ì—°ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- **application.yml**ì„ í†µí•´ LLM ëª¨ë¸ì„ ì„¤ì •í•˜ê³  êµì²´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- **í”„ë¡œí¼í‹° ì„¤ì •**ì„ í†µí•´ ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- **ì—¬ëŸ¬ LLMì„ ë™ì‹œì—** ì‚¬ìš©í•˜ê³  ì„ íƒì ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- **LLM ê°„ ì°¨ì´ì **ì„ ì´í•´í•˜ê³  ìƒí™©ì— ë§ê²Œ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤

---

## ğŸ”‘ í•µì‹¬ í‚¤ì›Œë“œ

ì´ ì¥ì—ì„œ ë‹¤ë£¨ëŠ” í•µì‹¬ í‚¤ì›Œë“œë“¤:

1. **application.yml** - Spring Boot ì„¤ì • íŒŒì¼
2. **í”„ë¡œí¼í‹° ì„¤ì •** - ëª¨ë¸ íŒŒë¼ë¯¸í„° êµ¬ì„±
3. **ChatModel** - LLM ì¶”ìƒí™” ì¸í„°í˜ì´ìŠ¤
4. **@Primary** - ê¸°ë³¸ Bean ì§€ì •
5. **Qualifier** - íŠ¹ì • Bean ì„ íƒ

---

## 1. Spring AIì—ì„œ ì§€ì›í•˜ëŠ” LLM ì œê³µì

### 1.1 ì£¼ìš” LLM ì œê³µì

Spring AIëŠ” ë‹¤ì–‘í•œ LLM ì œê³µìë¥¼ ì§€ì›í•©ë‹ˆë‹¤:

| ì œê³µì | ëª¨ë¸ ì˜ˆì‹œ | íŠ¹ì§• | ë¹„ìš© |
|--------|----------|------|------|
| **OpenAI** | GPT-4, GPT-3.5-turbo | ë„ë¦¬ ì‚¬ìš©ë¨, ë†’ì€ í’ˆì§ˆ | ìœ ë£Œ |
| **Anthropic** | Claude 3 (Sonnet, Opus, Haiku) | ê¸´ ì»¨í…ìŠ¤íŠ¸, ì•ˆì „ì„± ì¤‘ì‹œ | ìœ ë£Œ |
| **Ollama** | Llama 2, Mistral, CodeLlama | ë¡œì»¬ ì‹¤í–‰, ë¬´ë£Œ | ë¬´ë£Œ |
| **Azure OpenAI** | GPT-4, GPT-3.5 | ì—”í„°í”„ë¼ì´ì¦ˆ ì§€ì› | ìœ ë£Œ |
| **Vertex AI** | Gemini, PaLM | Google Cloud í†µí•© | ìœ ë£Œ |

### 1.2 ê° ì œê³µìì˜ íŠ¹ì§•

#### OpenAI
- **ì¥ì **: 
  - ê°€ì¥ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ëª¨ë¸
  - ë†’ì€ ì‘ë‹µ í’ˆì§ˆ
  - Vision ëª¨ë¸ ì§€ì› (GPT-4o)
  - ë¹ ë¥¸ ì‘ë‹µ ì†ë„
- **ë‹¨ì **: 
  - ìœ ë£Œ ì„œë¹„ìŠ¤
  - API ì‚¬ìš©ëŸ‰ ì œí•œ

#### Anthropic (Claude)
- **ì¥ì **:
  - ê¸´ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° (ìµœëŒ€ 200K í† í°)
  - ì•ˆì „ì„± ì¤‘ì‹¬ ì„¤ê³„
  - ë†’ì€ í’ˆì§ˆì˜ ì‘ë‹µ
- **ë‹¨ì **:
  - ìœ ë£Œ ì„œë¹„ìŠ¤
  - ëª¨ë¸ ì„ íƒì´ ì œí•œì 

#### Ollama
- **ì¥ì **:
  - ì™„ì „ ë¬´ë£Œ
  - ë¡œì»¬ ì‹¤í–‰ (í”„ë¼ì´ë²„ì‹œ ë³´í˜¸)
  - ì¸í„°ë„· ì—°ê²° ë¶ˆí•„ìš”
  - ë‹¤ì–‘í•œ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸
- **ë‹¨ì **:
  - ë¡œì»¬ ë¦¬ì†ŒìŠ¤ í•„ìš”
  - ì‘ë‹µ í’ˆì§ˆì´ í´ë¼ìš°ë“œ ëª¨ë¸ë³´ë‹¤ ë‚®ì„ ìˆ˜ ìˆìŒ

---

## 2. OpenAI ì—°ë™í•˜ê¸°

### 2.1 ì˜ì¡´ì„± ì¶”ê°€

`build.gradle.kts`ì— ì˜ì¡´ì„± ì¶”ê°€:

```kotlin
dependencies {
    implementation("org.springframework.ai:spring-ai-openai-spring-boot-starter:1.0.0-M6")
}
```

### 2.2 application.yml ì„¤ì •

```yaml
spring:
  ai:
    openai:
      api-key: ${OPENAI_API_KEY}
      chat:
        options:
          model: gpt-4          # ë˜ëŠ” gpt-3.5-turbo, gpt-4-turbo
          temperature: 0.7      # 0.0 ~ 2.0
          max-tokens: 1000
          top-p: 1.0
          frequency-penalty: 0.0
          presence-penalty: 0.0
```

### 2.3 í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
export OPENAI_API_KEY="sk-your-api-key-here"
```

### 2.4 ì‚¬ìš© ì˜ˆì œ

```kotlin
@RestController
class OpenAIController(
    private val chatModel: ChatModel  // ìë™ìœ¼ë¡œ OpenAI ChatModel ì£¼ì…
) {
    @GetMapping("/openai")
    fun chat(): String {
        val prompt = Prompt(UserMessage("ì•ˆë…•í•˜ì„¸ìš”!"))
        val response = chatModel.call(prompt)
        return response.results.firstOrNull()?.output?.text ?: "ì‘ë‹µ ì—†ìŒ"
    }
}
```

---

## 3. Anthropic (Claude) ì—°ë™í•˜ê¸°

### 3.1 ì˜ì¡´ì„± ì¶”ê°€

```kotlin
dependencies {
    implementation("org.springframework.ai:spring-ai-anthropic-spring-boot-starter:1.0.0-M6")
}
```

### 3.2 application.yml ì„¤ì •

```yaml
spring:
  ai:
    anthropic:
      api-key: ${ANTHROPIC_API_KEY}
      chat:
        options:
          model: claude-3-sonnet-20240229  # ë˜ëŠ” claude-3-opus, claude-3-haiku
          temperature: 0.7
          max-tokens: 1000
```

### 3.3 í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
export ANTHROPIC_API_KEY="sk-ant-your-api-key-here"
```

### 3.4 ì‚¬ìš© ì˜ˆì œ

```kotlin
@RestController
class AnthropicController(
    private val chatModel: ChatModel  // Anthropic ChatModel ì£¼ì…
) {
    @GetMapping("/anthropic")
    fun chat(): String {
        val prompt = Prompt(UserMessage("ì•ˆë…•í•˜ì„¸ìš”!"))
        val response = chatModel.call(prompt)
        return response.results.firstOrNull()?.output?.text ?: "ì‘ë‹µ ì—†ìŒ"
    }
}
```

---

## 4. Ollama (ë¡œì»¬ LLM) ì—°ë™í•˜ê¸°

### 4.1 Ollama ì„¤ì¹˜

**macOS:**
```bash
brew install ollama
```

**Linux:**
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

**Windows:**
[Ollama ê³µì‹ ì‚¬ì´íŠ¸](https://ollama.ai/)ì—ì„œ ë‹¤ìš´ë¡œë“œ

### 4.2 Ollama ì‹¤í–‰ ë° ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

```bash
# Ollama ì„œë²„ ì‹œì‘
ollama serve

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ë³„ë„ í„°ë¯¸ë„)
ollama pull llama2
ollama pull mistral
ollama pull codellama
```

### 4.3 ì˜ì¡´ì„± ì¶”ê°€

```kotlin
dependencies {
    implementation("org.springframework.ai:spring-ai-ollama-spring-boot-starter:1.0.0-M6")
}
```

### 4.4 application.yml ì„¤ì •

```yaml
spring:
  ai:
    ollama:
      base-url: http://localhost:11434  # Ollama ê¸°ë³¸ URL
      chat:
        options:
          model: llama2        # ë‹¤ìš´ë¡œë“œí•œ ëª¨ë¸ ì´ë¦„
          temperature: 0.7
```

### 4.5 ì‚¬ìš© ì˜ˆì œ

```kotlin
@RestController
class OllamaController(
    private val chatModel: ChatModel  // Ollama ChatModel ì£¼ì…
) {
    @GetMapping("/ollama")
    fun chat(): String {
        val prompt = Prompt(UserMessage("ì•ˆë…•í•˜ì„¸ìš”!"))
        val response = chatModel.call(prompt)
        return response.results.firstOrNull()?.output?.text ?: "ì‘ë‹µ ì—†ìŒ"
    }
}
```

---

## 5. ì—¬ëŸ¬ LLM ë™ì‹œ ì‚¬ìš©í•˜ê¸°

### 5.1 ì™œ ì—¬ëŸ¬ LLMì„ ì‚¬ìš©í•˜ëŠ”ê°€?

- **ë¹„ìš© ìµœì í™”**: ê°„ë‹¨í•œ ì§ˆë¬¸ì€ ë¬´ë£Œ Ollama, ë³µì¡í•œ ì§ˆë¬¸ì€ ìœ ë£Œ ëª¨ë¸
- **ì„±ëŠ¥ ë¹„êµ**: ì—¬ëŸ¬ ëª¨ë¸ì˜ ì‘ë‹µì„ ë¹„êµ
- **ì¥ì•  ë³µêµ¬**: í•œ ëª¨ë¸ì´ ì‹¤íŒ¨í•˜ë©´ ë‹¤ë¥¸ ëª¨ë¸ë¡œ ëŒ€ì²´
- **íŠ¹í™”ëœ ìš©ë„**: ìš©ë„ë³„ë¡œ ë‹¤ë¥¸ ëª¨ë¸ ì‚¬ìš©

### 5.2 ì—¬ëŸ¬ ì˜ì¡´ì„± ì¶”ê°€

```kotlin
dependencies {
    implementation("org.springframework.ai:spring-ai-openai-spring-boot-starter:1.0.0-M6")
    implementation("org.springframework.ai:spring-ai-ollama-spring-boot-starter:1.0.0-M6")
}
```

### 5.3 application.yml ì„¤ì •

```yaml
spring:
  ai:
    openai:
      api-key: ${OPENAI_API_KEY}
      chat:
        options:
          model: gpt-4
    ollama:
      base-url: http://localhost:11434
      chat:
        options:
          model: llama2
```

### 5.4 ê¸°ë³¸ ëª¨ë¸ ìë™ ì„¤ì •

Spring Boot ìë™ ì„¤ì •ì´ ê° Starterì— ë”°ë¼ ChatModel Beanì„ ìë™ ìƒì„±í•©ë‹ˆë‹¤:

- **OpenAI Starter**: `ChatModel` Beanì´ ìë™ ìƒì„± (ì¼ë°˜ì ìœ¼ë¡œ `@Primary`)
- **Ollama Starter**: `ollamaChatModel` Beanì´ ìë™ ìƒì„± (Bean ì´ë¦„: "ollamaChatModel")
- **Anthropic Starter**: `ChatModel` Beanì´ ìë™ ìƒì„±

> ğŸ’¡ **ì°¸ê³ **: ì‹¤ì œë¡œëŠ” ë³„ë„ì˜ Configurationì´ í•„ìš” ì—†ìŠµë‹ˆë‹¤. Spring Boot ìë™ ì„¤ì •ì´ ëª¨ë“  ê²ƒì„ ì²˜ë¦¬í•©ë‹ˆë‹¤. ì»¤ìŠ¤í…€ ì„¤ì •ì´ í•„ìš”í•œ ê²½ìš°ì—ë§Œ Configuration í´ë˜ìŠ¤ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

### 5.5 Qualifierë¡œ íŠ¹ì • ëª¨ë¸ ì„ íƒ

Spring AI 1.0.0-M6ì—ì„œëŠ” Ollama ChatModelì´ ìë™ìœ¼ë¡œ `ollamaChatModel`ì´ë¼ëŠ” ì´ë¦„ì˜ Beanìœ¼ë¡œ ë“±ë¡ë©ë‹ˆë‹¤:

```kotlin
@RestController
class MultiModelController(
    private val chatModel: ChatModel,  // ê¸°ë³¸ ëª¨ë¸ (OpenAI, @Primary)
    @Qualifier("ollamaChatModel") 
    private val ollamaChatModel: ChatModel? = null  // Ollama ëª¨ë¸ (ì„ íƒì )
) {
    @GetMapping("/chat/openai")
    fun chatWithOpenAI(): String {
        val prompt = Prompt(UserMessage("ì•ˆë…•í•˜ì„¸ìš”!"))
        val response = chatModel.call(prompt)
        return response.results.firstOrNull()?.output?.text ?: "ì‘ë‹µ ì—†ìŒ"
    }
    
    @GetMapping("/chat/ollama")
    fun chatWithOllama(): String {
        if (ollamaChatModel == null) {
            return "Ollama is not configured"
        }
        val prompt = Prompt(UserMessage("ì•ˆë…•í•˜ì„¸ìš”!"))
        val response = ollamaChatModel.call(prompt)
        return response.results.firstOrNull()?.output?.text ?: "ì‘ë‹µ ì—†ìŒ"
    }
}
```

> ğŸ’¡ **ì£¼ì˜**: Ollama Starterê°€ ì—†ìœ¼ë©´ `ollamaChatModel` Beanì´ ìƒì„±ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ nullableë¡œ ì„ ì–¸í•˜ê±°ë‚˜ `@Autowired(required = false)`ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

### 5.6 ëª¨ë¸ ì„ íƒ ë¡œì§ êµ¬í˜„

ì‹¤ì œ êµ¬í˜„ ì˜ˆì œ (sample ì½”ë“œ ì°¸ê³ ):

```kotlin
@Service
class ModelSelectorService(
    private val primaryChatModel: ChatModel,  // ê¸°ë³¸ ëª¨ë¸ (OpenAI)
    @Qualifier("ollamaChatModel")
    private val ollamaChatModel: ChatModel? = null  // Ollama (ì„ íƒì )
) {
    fun selectModel(question: String): ChatModel {
        return when {
            // ê°„ë‹¨í•œ ì§ˆë¬¸ì€ Ollama (ë¬´ë£Œ) - ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°
            question.length < 50 && ollamaChatModel != null -> ollamaChatModel
            // ë³µì¡í•œ ì§ˆë¬¸ì€ ê¸°ë³¸ ëª¨ë¸ (OpenAI)
            else -> primaryChatModel
        }
    }
    
    fun smartChat(message: String): Map<String, Any> {
        val model = selectModel(message)
        val modelName = if (model == ollamaChatModel) "Ollama" else "Primary (OpenAI)"
        
        val prompt = Prompt(UserMessage(message))
        val response = model.call(prompt)
        
        return mapOf(
            "selectedModel" to modelName,
            "message" to (response.results.firstOrNull()?.output?.text ?: "ì‘ë‹µ ì—†ìŒ"),
            "questionLength" to message.length
        )
    }
}
```

---

## 6. ëª¨ë¸ íŒŒë¼ë¯¸í„° ì„¤ì •

### 6.1 ì£¼ìš” íŒŒë¼ë¯¸í„° ì„¤ëª…

#### Temperature (ì˜¨ë„)
- **ë²”ìœ„**: 0.0 ~ 2.0
- **ì˜ë¯¸**: ì‘ë‹µì˜ ì°½ì˜ì„±/ëœë¤ì„± ì¡°ì ˆ
- **ë‚®ì€ ê°’ (0.0-0.3)**: ì¼ê´€ì ì´ê³  ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì‘ë‹µ
- **ì¤‘ê°„ ê°’ (0.7-1.0)**: ê· í˜•ì¡íŒ ì‘ë‹µ
- **ë†’ì€ ê°’ (1.5-2.0)**: ì°½ì˜ì ì´ê³  ë‹¤ì–‘í•œ ì‘ë‹µ

```yaml
temperature: 0.7  # ê¶Œì¥ê°’
```

#### Max Tokens
- **ì˜ë¯¸**: ìµœëŒ€ ìƒì„±í•  í† í° ìˆ˜
- **ì˜í–¥**: ì‘ë‹µì˜ ê¸¸ì´ ì œí•œ
- **ì£¼ì˜**: ë„ˆë¬´ ì‘ìœ¼ë©´ ì‘ë‹µì´ ì˜ë¦´ ìˆ˜ ìˆìŒ

```yaml
max-tokens: 1000  # ì¼ë°˜ì ì¸ ì„¤ì •
```

#### Top-P (Nucleus Sampling)
- **ë²”ìœ„**: 0.0 ~ 1.0
- **ì˜ë¯¸**: í™•ë¥  ë¶„í¬ì˜ ìƒìœ„ P%ë§Œ ê³ ë ¤
- **íš¨ê³¼**: ì‘ë‹µ ë‹¤ì–‘ì„± ì¡°ì ˆ

```yaml
top-p: 1.0  # ëª¨ë“  í† í° ê³ ë ¤
```

### 6.2 ìš©ë„ë³„ ê¶Œì¥ ì„¤ì •

#### ì •í™•í•œ ì •ë³´ ìš”ì²­
```yaml
temperature: 0.0
max-tokens: 500
top-p: 0.9
```

#### ì°½ì˜ì  ê¸€ì“°ê¸°
```yaml
temperature: 1.2
max-tokens: 2000
top-p: 1.0
```

#### ì½”ë”© ì§ˆë¬¸
```yaml
temperature: 0.2
max-tokens: 1500
top-p: 0.95
```

---

## 7. í™˜ê²½ë³„ ì„¤ì • ê´€ë¦¬

### 7.1 í”„ë¡œíŒŒì¼ ì‚¬ìš©

#### application-dev.yml (ê°œë°œ í™˜ê²½)
```yaml
spring:
  ai:
    ollama:  # ë¬´ë£Œ ëª¨ë¸ ì‚¬ìš©
      base-url: http://localhost:11434
      chat:
        options:
          model: llama2
```

#### application-prod.yml (ìš´ì˜ í™˜ê²½)
```yaml
spring:
  ai:
    openai:  # ìœ ë£Œ ëª¨ë¸ ì‚¬ìš©
      api-key: ${OPENAI_API_KEY}
      chat:
        options:
          model: gpt-4
```

### 7.2 í”„ë¡œíŒŒì¼ í™œì„±í™”

```bash
# ê°œë°œ í™˜ê²½
java -jar app.jar --spring.profiles.active=dev

# ìš´ì˜ í™˜ê²½
java -jar app.jar --spring.profiles.active=prod
```

---

## 8. ëª¨ë¸ ë¹„êµ ë° ì„ íƒ ê°€ì´ë“œ

### 8.1 ìƒí™©ë³„ ëª¨ë¸ ì„ íƒ

| ìƒí™© | ì¶”ì²œ ëª¨ë¸ | ì´ìœ  |
|------|----------|------|
| **ê°œë°œ/í…ŒìŠ¤íŠ¸** | Ollama | ë¬´ë£Œ, ë¹ ë¥¸ ë°˜ë³µ í…ŒìŠ¤íŠ¸ |
| **í”„ë¡œë•ì…˜** | OpenAI GPT-4 | ë†’ì€ í’ˆì§ˆ, ì•ˆì •ì„± |
| **ê¸´ ë¬¸ì„œ ë¶„ì„** | Anthropic Claude | ê¸´ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° |
| **ë¹„ìš© ìµœì í™”** | Ollama + OpenAI ì¡°í•© | ìš©ë„ë³„ ì„ íƒ |
| **í”„ë¼ì´ë²„ì‹œ ì¤‘ìš”** | Ollama | ë¡œì»¬ ì‹¤í–‰ |

### 8.2 ëª¨ë¸ ë¹„êµ í…ŒìŠ¤íŠ¸

ì‹¤ì œ êµ¬í˜„ ì˜ˆì œ (sampleì˜ MultiModelController ì°¸ê³ ):

```kotlin
@RestController
class MultiModelController(
    private val primaryChatModel: ChatModel,
    @Qualifier("ollamaChatModel")
    private val ollamaChatModel: ChatModel? = null
) {
    @GetMapping("/compare")
    fun compareModels(@RequestParam message: String): Map<String, Any> {
        val prompt = Prompt(UserMessage(message))
        
        val defaultResponse = primaryChatModel.call(prompt)
        val defaultText = defaultResponse.results.firstOrNull()?.output?.text ?: "ì‘ë‹µ ì—†ìŒ"
        
        val result = mutableMapOf<String, Any>(
            "default" to mapOf(
                "model" to "Primary",
                "message" to defaultText
            )
        )
        
        if (ollamaChatModel != null) {
            val ollamaResponse = ollamaChatModel.call(prompt)
            val ollamaText = ollamaResponse.results.firstOrNull()?.output?.text ?: "ì‘ë‹µ ì—†ìŒ"
            
            result["ollama"] = mapOf(
                "model" to "Ollama",
                "message" to ollamaText
            )
        }
        
        return result
    }
}
```

---

## 9. ì‹¤ì „ ì˜ˆì œ

### 9.1 LLM ì„ íƒ ì„œë¹„ìŠ¤

ì‹¤ì œ êµ¬í˜„ì€ sampleì˜ `ModelSelectorService`ë¥¼ ì°¸ê³ í•˜ì„¸ìš”. í™˜ê²½ë³„ ì„ íƒ ì˜ˆì œ:

```kotlin
@Service
class LLMSelectionService(
    private val primaryChatModel: ChatModel,
    @Qualifier("ollamaChatModel")
    private val ollamaChatModel: ChatModel?,
    private val environment: Environment
) {
    fun getBestModel(): ChatModel {
        // í™˜ê²½ì— ë”°ë¼ ëª¨ë¸ ì„ íƒ
        val activeProfile = environment.activeProfiles.firstOrNull()
        
        return when (activeProfile) {
            "dev", "ollama" -> ollamaChatModel ?: primaryChatModel
            "prod" -> primaryChatModel
            else -> primaryChatModel
        }
    }
}
```

> ğŸ’¡ **ì°¸ê³ **: ì‹¤ì œë¡œëŠ” íƒ€ì… ì²´í¬ë³´ë‹¤ëŠ” Bean ì´ë¦„(@Qualifier)ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ë” ì•ˆì „í•©ë‹ˆë‹¤.

### 9.2 ëª¨ë¸ ìƒíƒœ ì²´í¬

```kotlin
@Component
class ModelHealthChecker(
    @Qualifier("ollamaChatModel")
    private val ollamaChatModel: ChatModel? = null
) {
    @Scheduled(fixedRate = 60000)  // 1ë¶„ë§ˆë‹¤ ì²´í¬
    fun checkOllamaHealth() {
        if (ollamaChatModel == null) {
            logger.warn("Ollama is not configured")
            return
        }
        
        try {
            val prompt = Prompt(UserMessage("test"))
            ollamaChatModel.call(prompt)
            logger.info("Ollama is healthy")
        } catch (e: Exception) {
            logger.error("Ollama is not available: ${e.message}")
        }
    }
}
```

> ğŸ’¡ **ì°¸ê³ **: `@Scheduled`ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ `@EnableScheduling`ì„ ë©”ì¸ í´ë˜ìŠ¤ì— ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.

---

## 10. íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 10.1 ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

#### ë¬¸ì œ 1: ì—¬ëŸ¬ ChatModel Bean ì¶©ëŒ

```
NoUniqueBeanDefinitionException: No qualifying bean of type 'ChatModel' available
```

**ì›ì¸**: ì—¬ëŸ¬ LLM Starterë¥¼ ì¶”ê°€í–ˆì§€ë§Œ ê¸°ë³¸ Beanì´ ì§€ì •ë˜ì§€ ì•ŠìŒ

**í•´ê²°ì±…**:
- OpenAI StarterëŠ” ìë™ìœ¼ë¡œ `@Primary` ChatModel Beanì„ ìƒì„±í•©ë‹ˆë‹¤
- OllamaëŠ” ìë™ìœ¼ë¡œ `ollamaChatModel` Beanì„ ìƒì„±í•©ë‹ˆë‹¤
- í•„ìš”ì‹œ ëª…ì‹œì ìœ¼ë¡œ `@Primary` ì§€ì •:
```kotlin
@Configuration
class ChatModelConfig {
    @Bean
    @Primary
    fun primaryChatModel(properties: OpenAiChatProperties): ChatModel {
        // ê¸°ë³¸ ëª¨ë¸ ì§€ì • (ì¼ë°˜ì ìœ¼ë¡œ ìë™ ì„¤ì •ìœ¼ë¡œ ì¶©ë¶„)
        return OpenAiChatModel(properties)
    }
}
```

#### ë¬¸ì œ 2: Ollama ì—°ê²° ì‹¤íŒ¨

```
Connection refused: localhost:11434
```

**ì›ì¸**: Ollama ì„œë²„ê°€ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ

**í•´ê²°ì±…**:
```bash
# Ollama ì„œë²„ ì‹œì‘
ollama serve
```

#### ë¬¸ì œ 3: API Key ì˜¤ë¥˜

```
Invalid API Key
```

**ì›ì¸**: ì˜ëª»ëœ API Key ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜ ë¯¸ì„¤ì •

**í•´ê²°ì±…**:
- í™˜ê²½ ë³€ìˆ˜ í™•ì¸: `echo $OPENAI_API_KEY`
- application.ymlì—ì„œ ì§ì ‘ ì„¤ì • (ê°œë°œ í™˜ê²½ë§Œ)

---

## 11. ìš”ì•½

### 11.1 í•µì‹¬ ë‚´ìš© ì •ë¦¬

1. **OpenAI**: ê°€ì¥ ë„ë¦¬ ì‚¬ìš©, ë†’ì€ í’ˆì§ˆ, ìœ ë£Œ
2. **Anthropic**: ê¸´ ì»¨í…ìŠ¤íŠ¸, ì•ˆì „ì„±, ìœ ë£Œ
3. **Ollama**: ë¡œì»¬ ì‹¤í–‰, ë¬´ë£Œ, í”„ë¼ì´ë²„ì‹œ ë³´í˜¸
4. **ì—¬ëŸ¬ ëª¨ë¸ ë™ì‹œ ì‚¬ìš©**: `@Primary`, `@Qualifier` í™œìš©
5. **í”„ë¡œíŒŒì¼ í™œìš©**: í™˜ê²½ë³„ ë‹¤ë¥¸ ëª¨ë¸ ì‚¬ìš©

### 11.2 ì„¤ì • íŒ¨í„´

```yaml
# ë‹¨ì¼ ëª¨ë¸ ì‚¬ìš©
spring:
  ai:
    openai:
      api-key: ${OPENAI_API_KEY}
      chat:
        options:
          model: gpt-4
          temperature: 0.7
```

### 11.3 ë‹¤ìŒ í•™ìŠµ ë‚´ìš©

ì´ì œ ë‹¤ì–‘í•œ LLMì„ ì—°ë™í•˜ëŠ” ë°©ë²•ì„ ë°°ì› ìœ¼ë‹ˆ, ë‹¤ìŒ ì¥ì—ì„œëŠ”:
- **PromptTemplate**: ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„±
- **í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§**: ë” ë‚˜ì€ ì‘ë‹µì„ ìœ„í•œ ê¸°ë²•

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [Spring AI ê³µì‹ ë ˆí¼ëŸ°ìŠ¤](https://docs.spring.io/spring-ai/reference/)
- [OpenAI API ë¬¸ì„œ](https://platform.openai.com/docs)
- [Anthropic API ë¬¸ì„œ](https://docs.anthropic.com/)
- [Ollama ê³µì‹ ì‚¬ì´íŠ¸](https://ollama.ai/)

---

## â“ í•™ìŠµ í™•ì¸ ë¬¸ì œ

ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•´ë³´ì„¸ìš”:

1. OpenAIì™€ Ollamaì˜ ì£¼ìš” ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?
2. ì—¬ëŸ¬ LLMì„ ë™ì‹œì— ì‚¬ìš©í•  ë•Œ `@Primary`ì™€ `@Qualifier`ì˜ ì—­í• ì€?
3. Temperature íŒŒë¼ë¯¸í„°ê°€ ì‘ë‹µì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹˜ë‚˜ìš”?
4. ê°œë°œ í™˜ê²½ê³¼ ìš´ì˜ í™˜ê²½ì—ì„œ ë‹¤ë¥¸ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?
5. Ollamaë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ì‚¬ì „ ì¤€ë¹„ì‚¬í•­ì€ ë¬´ì—‡ì¸ê°€ìš”?

---

**ë‹¤ìŒ ì¥**: [3ì¥: íš¨ê³¼ì ì¸ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§](../README.md#3ì¥-íš¨ê³¼ì ì¸-í”„ë¡¬í”„íŠ¸-ì—”ì§€ë‹ˆì–´ë§-prompttemplate)

