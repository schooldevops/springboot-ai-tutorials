# ChatModel 샘플 프로젝트 실행 가이드

이 가이드는 2.1.ChatModel 샘플 프로젝트를 실행하고 테스트하는 방법을 안내합니다.

## 📋 사전 준비사항

- JDK 17 이상 설치
- OpenAI API Key 발급
- 환경 변수 설정 권한

## 🚀 실행 방법

### 1. 환경 변수 설정

터미널에서 API Key를 환경 변수로 설정:

**macOS / Linux:**
```bash
export OPENAI_API_KEY="sk-your-api-key-here"
```

**Windows (PowerShell):**
```powershell
$env:OPENAI_API_KEY="sk-your-api-key-here"
```

### 2. 프로젝트 실행

```bash
./gradlew bootRun
```

또는 IntelliJ IDEA에서 `ChatModelDemoApplication.kt` 실행

### 3. 실행 확인

애플리케이션이 정상적으로 시작되면 다음과 같은 메시지가 표시됩니다:

```
Started ChatModelDemoApplication in X.XXX seconds
```

## 🧪 API 테스트

### 기본 사용 예제

#### 1. 기본 ChatModel 사용 (GET)

```bash
curl http://localhost:8080/api/simple/basic
```

**예상 응답:**
```
안녕하세요! 저는 AI 어시스턴트입니다...
```

#### 2. POST 요청으로 질문하기

```bash
curl -X POST http://localhost:8080/api/simple/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Spring AI에 대해 설명해주세요"}'
```

**예상 응답:**
```json
{
  "message": "Spring AI는 Spring 생태계의 AI 통합 프레임워크입니다..."
}
```

#### 3. 안전한 호출 테스트

```bash
curl -X POST http://localhost:8080/api/simple/safe \
  -H "Content-Type: application/json" \
  -d '{"message": "Kotlin의 주요 특징은?"}'
```

### 고급 사용 예제

#### 4. 대화 이력 예제

```bash
curl http://localhost:8080/api/advanced/conversation
```

이 예제는 여러 메시지를 포함한 대화를 보여줍니다.

#### 5. 역할 기반 챗봇

```bash
curl -X POST http://localhost:8080/api/advanced/role \
  -H "Content-Type: application/json" \
  -d '{
    "role": "teacher",
    "message": "프로그래밍을 처음 배우는 학생에게 조언해주세요"
  }'
```

**사용 가능한 역할:**
- `teacher`: 선생님 역할
- `doctor`: 의사 역할
- `chef`: 셰프 역할
- 기타: 기본 어시스턴트

#### 6. 대화 이력 관리

```bash
curl -X POST http://localhost:8080/api/advanced/history \
  -H "Content-Type: application/json" \
  -d '{
    "sessionId": "user123",
    "message": "안녕하세요"
  }'
```

#### 7. 메타데이터 확인

```bash
curl http://localhost:8080/api/advanced/metadata
```

### 확장 함수 사용 예제

#### 8. 간단한 확장 함수

```bash
curl "http://localhost:8080/api/extension/simple?message=안녕하세요"
```

#### 9. 안전한 호출 확장 함수

```bash
curl "http://localhost:8080/api/extension/safe?message=Kotlin이란?"
```

**예상 응답:**
```json
{
  "success": true,
  "message": "Kotlin은 JVM에서 실행되는 현대적인 프로그래밍 언어입니다..."
}
```

#### 10. 여러 메시지 전송

```bash
curl http://localhost:8080/api/extension/multi
```

## 📊 Postman 사용

Postman을 사용하는 경우 다음 Collection을 가져올 수 있습니다:

1. 새 Collection 생성: "ChatModel Examples"
2. 다음 요청 추가:

### 요청 예시

**1. Basic Chat**
- Method: GET
- URL: `http://localhost:8080/api/simple/basic`

**2. Post Chat**
- Method: POST
- URL: `http://localhost:8080/api/simple/chat`
- Headers: `Content-Type: application/json`
- Body (raw JSON):
```json
{
  "message": "Spring AI에 대해 설명해주세요"
}
```

**3. Role Based Chat**
- Method: POST
- URL: `http://localhost:8080/api/advanced/role`
- Body:
```json
{
  "role": "teacher",
  "message": "수학 공부 방법을 알려주세요"
}
```

## 🔍 디버깅

### 로그 확인

애플리케이션 실행 시 로그를 확인하여 디버깅할 수 있습니다:

```yaml
# application.yml에 이미 설정됨
logging:
  level:
    com.example.springai: DEBUG
    org.springframework.ai: DEBUG
```

### 응답 구조 확인

`AdvancedChatController`의 `/api/advanced/metadata` 엔드포인트를 사용하여 응답 구조를 확인할 수 있습니다.

## ❌ 문제 해결

### 문제 1: API Key 오류

**증상:**
```
Error: API key not found
```

**해결책:**
1. 환경 변수 확인: `echo $OPENAI_API_KEY`
2. 애플리케이션 재시작

### 문제 2: 포트 충돌

**증상:**
```
Port 8080 is already in use
```

**해결책:**
`application.yml`에서 포트 변경:
```yaml
server:
  port: 8081
```

### 문제 3: Null 응답

**증상:**
응답이 "응답을 생성할 수 없습니다."로 반환됨

**해결책:**
- API Key가 올바른지 확인
- 모델이 사용 가능한지 확인 (gpt-4 또는 gpt-3.5-turbo)
- 네트워크 연결 확인

## ✅ 체크리스트

실행 전 확인사항:

- [ ] JDK 17 이상 설치됨
- [ ] OpenAI API Key 발급됨
- [ ] 환경 변수 설정됨
- [ ] 프로젝트 빌드 성공 (`./gradlew build`)
- [ ] 애플리케이션 실행 성공 (`./gradlew bootRun`)
- [ ] API 엔드포인트 응답 확인

## 🎓 학습 권장 순서

1. **기본 사용법**: `/api/simple/basic`, `/api/simple/chat`
2. **고급 사용법**: `/api/advanced/conversation`, `/api/advanced/role`
3. **확장 함수**: `/api/extension/*` 엔드포인트들
4. **코드 분석**: 각 컨트롤러의 코드를 읽어보며 학습

## 📚 다음 단계

이 샘플 프로젝트를 성공적으로 실행했다면:

1. ✅ ChatModel의 기본 사용법을 이해했습니다
2. ✅ Prompt와 ChatResponse의 구조를 이해했습니다
3. ✅ Kotlin의 확장 함수를 활용할 수 있습니다
4. ✅ 다음 장으로 진행할 준비가 되었습니다!

**다음 학습**: [2.2: 다양한 LLM 모델 연동하기](../../README.md#22-다양한-llm-모델-연동하기)

