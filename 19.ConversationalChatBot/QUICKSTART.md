# ğŸš€ Quick Start Guide

## Prerequisites

- â˜• Java 17 or higher
- ğŸ¦™ Ollama with Llama model

## Setup Steps

### 1. Install and Start Ollama

```bash
ollama serve
ollama pull llama3.2
```

### 2. Run Tests (TDD Verification)

```bash
cd 19.ConversationalChatBot/sample
./gradlew test

# Expected output:
# ChatHistoryServiceTest > should store and retrieve chat history PASSED
# ChatHistoryServiceTest > should maintain separate histories for different sessions PASSED
# ChatHistoryServiceTest > should clear history for specific session PASSED
# ChatHistoryServiceTest > should return empty list for non-existent session PASSED
# BUILD SUCCESSFUL
# 4 tests completed
```

### 3. Run the Application

```bash
./gradlew bootRun
```

## Testing Conversational Chat

### Scenario: Context-aware Conversation

```bash
# Turn 1: Introduce yourself
curl -X POST http://localhost:8080/api/chat \
  -H "Content-Type: application/json" \
  -d '{"sessionId": "user-123", "message": "ë‚´ ì´ë¦„ì€ ê¹€ì² ìˆ˜ì•¼"}'

# Response: "ì•ˆë…•í•˜ì„¸ìš” ê¹€ì² ìˆ˜ë‹˜!"

# Turn 2: Ask about name (AI remembers from Turn 1)
curl -X POST http://localhost:8080/api/chat \
  -H "Content-Type: application/json" \
  -d '{"sessionId": "user-123", "message": "ë‚´ ì´ë¦„ì´ ë­ì˜€ì§€?"}'

# Response: "ê¹€ì² ìˆ˜ë‹˜ì´ë¼ê³  í•˜ì…¨ìŠµë‹ˆë‹¤."

# Turn 3: Continue conversation
curl -X POST http://localhost:8080/api/chat \
  -H "Content-Type: application/json" \
  -d '{"sessionId": "user-123", "message": "ê³ ë§ˆì›Œ"}'

# Response: "ì²œë§Œì—ìš”, ê¹€ì² ìˆ˜ë‹˜!"
```

## Key Features Demonstrated

### âœ… Chat History Management

AI remembers previous messages in the conversation.

### âœ… Session Isolation

Different users have separate conversation histories.

### âœ… Context Awareness

AI uses previous context to generate relevant responses.

## API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/api/chat/health` | Health check with active sessions |
| POST | `/api/chat` | Send message (with history) |
| GET | `/api/chat/{sessionId}/history` | View conversation history |
| DELETE | `/api/chat/{sessionId}` | Clear conversation history |

## Managing Chat History

### View History

```bash
curl http://localhost:8080/api/chat/user-123/history
```

**Response:**
```json
{
  "sessionId": "user-123",
  "messageCount": 6,
  "messages": [
    {"content": "ë‚´ ì´ë¦„ì€ ê¹€ì² ìˆ˜ì•¼"},
    {"content": "ì•ˆë…•í•˜ì„¸ìš” ê¹€ì² ìˆ˜ë‹˜!"},
    {"content": "ë‚´ ì´ë¦„ì´ ë­ì˜€ì§€?"},
    {"content": "ê¹€ì² ìˆ˜ë‹˜ì´ë¼ê³  í•˜ì…¨ìŠµë‹ˆë‹¤."}
  ]
}
```

### Clear History

```bash
curl -X DELETE http://localhost:8080/api/chat/user-123
```

## Troubleshooting

### Ollama Connection Error

```
Connection refused: localhost:11434
```

**Solution:**
```bash
ollama serve
```

### AI Not Remembering Context

**Check:**
1. Using same sessionId for all requests
2. History is being saved correctly
3. Ollama is running

## Next Steps

- ğŸ“– Read the full [README.md](README.md)
- ğŸ§ª Test different conversation scenarios
- ğŸ”§ Implement session expiration
- ğŸ“ Add persistent storage

## Tips

ğŸ’¡ **Session Management**: Use unique sessionId for each user

ğŸ’¡ **History Limit**: Consider limiting history to recent N messages

ğŸ’¡ **Persistence**: Implement database storage for production

## Support

- ğŸ“š [Spring AI ChatMemory](https://docs.spring.io/spring-ai/reference/concepts.html#_conversations)
